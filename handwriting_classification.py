# -*- coding: utf-8 -*-
"""Handwriting_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y5xyUn5DbxQIY1Je5fGAlyfY3PzIrWlH

# Dementia Handwriting Classification

## Old Dataset (skip this)
"""

!pip install transformers datasets evaluate
!pip install accelerate -U
!pip install transformers[torch]

from transformers import AutoImageProcessor, ResNetForImageClassification
import torch
from datasets import load_dataset

import numpy as np
import pandas as pd
import os
import random
import time
import matplotlib.pyplot as plt

from PIL import Image
from datasets import Dataset

def load_image(file_path):
    return Image.open(file_path)

alzheimers_files = os.listdir("/content/drive/MyDrive/spiral-patients")
control_files = os.listdir("/content/drive/MyDrive/spiral-control")
all_files = alzheimers_files + control_files
random.shuffle(all_files)

data = []

for file_name in all_files:
    if file_name in alzheimers_files:
        image_path = os.path.join("/content/drive/MyDrive/spiral-patients", file_name)
        label = 1
    else:
        image_path = os.path.join("/content/drive/MyDrive/spiral-control", file_name)
        label = 0

    data.append({"image" : load_image(image_path), "label" : label})

data

images = [data[i]['image'] for i in range(len(data))]
images[10]

labels = [data[i]['label'] for i in range(len(data))]
labels[10]

data = Dataset.from_dict({"image" : images, "label" : labels})
data

data = data.train_test_split(test_size=0.2)
data['test']

label2id = {"Control": 0, "Patient": 1}
id2label = {0: "Control", 1: "Patient"}

from transformers import AutoImageProcessor

checkpoint = "google/vit-base-patch16-224-in21k"
image_processor = AutoImageProcessor.from_pretrained(checkpoint)

from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor

normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)
size = (
    image_processor.size["shortest_edge"]
    if "shortest_edge" in image_processor.size
    else (image_processor.size["height"], image_processor.size["width"])
)
_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])

def transforms(examples):
    examples["pixel_values"] = [_transforms(img.convert("RGB")) for img in examples["image"]]
    del examples["image"]
    return examples

data = data.with_transform(transforms)

from transformers import DefaultDataCollator

data_collator = DefaultDataCollator()

import evaluate

accuracy = evaluate.load("accuracy")

import numpy as np

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return accuracy.compute(predictions=predictions, references=labels)

from transformers import AutoModelForImageClassification, TrainingArguments, Trainer

model = AutoModelForImageClassification.from_pretrained(
    checkpoint,
    num_labels=2,
    id2label=id2label,
    label2id=label2id,
)

training_args = TrainingArguments(
    output_dir="alzheimers_handwriting_model_3",
    remove_unused_columns=False,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=5e-5,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    per_device_eval_batch_size=4,
    num_train_epochs=10,
    warmup_ratio=0.1,
    logging_steps=10,
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    push_to_hub=False,
)

trainer = Trainer(
    model=model,
    args=training_args,
    data_collator=data_collator,
    train_dataset=data["train"],
    eval_dataset=data["test"],
    tokenizer=image_processor,
    compute_metrics=compute_metrics,
)

trainer.train()

control_test = Image.open("/content/drive/MyDrive/spiral-control/0068-3.jpg")
control_test

patient_test = Image.open("/content/drive/MyDrive/spiral-patients/0003-2.jpg")
patient_test

image_processor = AutoImageProcessor.from_pretrained("/content/alzheimers_handwriting_model_3/checkpoint-180")
inputs = image_processor(patient_test, return_tensors="pt")

model = AutoModelForImageClassification.from_pretrained("/content/alzheimers_handwriting_model_3/checkpoint-180")
with torch.no_grad():
    logits = model(**inputs).logits

predicted_label = logits.argmax(-1).item()
model.config.id2label[predicted_label]

testing = []

alzheimers_files = os.listdir("/content/drive/MyDrive/spiral-patients")
control_files = os.listdir("/content/drive/MyDrive/spiral-control")
all_files = alzheimers_files + control_files
random.shuffle(all_files)

for file_name in all_files:
    if file_name in alzheimers_files:
        image_path = os.path.join("/content/drive/MyDrive/spiral-patients", file_name)
        label = 1
    else:
        image_path = os.path.join("/content/drive/MyDrive/spiral-control", file_name)
        label = 0

    testing.append({"image" : load_image(image_path), "label" : label})

testing

id2label[1]

true_counter = 0
total = 0

for i in range(20, 40):
  image_processor = AutoImageProcessor.from_pretrained("/content/alzheimers_handwriting_model/checkpoint-54")
  inputs = image_processor(testing[i]['image'], return_tensors="pt")

  model = AutoModelForImageClassification.from_pretrained("/content/alzheimers_handwriting_model/checkpoint-54")
  with torch.no_grad():
    logits = model(**inputs).logits

  predicted_label = logits.argmax(-1).item()
  if model.config.id2label[predicted_label] == id2label[testing[i]['label']]:
    true_counter += 1
  total += 1
  print(i)

print(f"Accuracy is: {true_counter / total}")

blue_control = Image.open("/content/blue_control.jpg")
blue_patient = Image.open("/content/blue_patient.jpg")
black_control = Image.open("/content/black_control.jpg")
black_patient = Image.open("/content/black_patient.jpg")

image_processor = AutoImageProcessor.from_pretrained("/content/alzheimers_handwriting_model_3/checkpoint-180")
inputs = image_processor(black_control, return_tensors="pt")

model = AutoModelForImageClassification.from_pretrained("/content/alzheimers_handwriting_model_3/checkpoint-180")
with torch.no_grad():
    logits = model(**inputs).logits

predicted_label = logits.argmax(-1).item()
model.config.id2label[predicted_label]

"""## Testing new dataset"""

!pip install transformers datasets evaluate
!pip install accelerate -U
!pip install transformers[torch]

from google.colab import drive
drive.mount('/content/drive')

from transformers import AutoImageProcessor, ResNetForImageClassification
from transformers import AutoModelForImageClassification, TrainingArguments, Trainer
import torch
from datasets import load_dataset

import numpy as np
import pandas as pd
import os
import random
import time
import matplotlib.pyplot as plt

spiral_dataset = load_dataset("imagefolder", data_dir="/content/drive/MyDrive/drawings/spiral")
wave_dataset = load_dataset("imagefolder", data_dir="/content/drive/MyDrive/drawings/wave")

import datasets
data = datasets.concatenate_datasets([spiral_dataset["train"], wave_dataset["train"], spiral_dataset["test"], wave_dataset["test"]])
data = data.train_test_split(test_size=0.2)
data.shuffle()
data

print(data['train'][17]["label"])
data['train'][17]['image']

label2id = {"Control": 0, "Patient": 1}
id2label = {0: "Control", 1: "Patient"}

checkpoint = "google/vit-base-patch16-224-in21k"
image_processor = AutoImageProcessor.from_pretrained(checkpoint)

from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor

normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)
size = (
    image_processor.size["shortest_edge"]
    if "shortest_edge" in image_processor.size
    else (image_processor.size["height"], image_processor.size["width"])
)
_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])

def transforms(examples):
    examples["pixel_values"] = [_transforms(img.convert("RGB")) for img in examples["image"]]
    del examples["image"]
    return examples

data = data.with_transform(transforms)

import torchvision.transforms as transforms
from PIL import Image
pixels = data['train'][29]['pixel_values']
image = transforms.ToPILImage()(pixels)
image

data['train'][0]

from transformers import DefaultDataCollator

data_collator = DefaultDataCollator()

import evaluate

accuracy = evaluate.load("accuracy")

import numpy as np

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return accuracy.compute(predictions=predictions, references=labels)

from transformers import AutoModelForImageClassification, TrainingArguments, Trainer

model = ResNetForImageClassification.from_pretrained(
    checkpoint,
    num_labels=2,
    id2label=id2label,
    label2id=label2id,
)

training_args = TrainingArguments(
    output_dir="new_alzheimers_handwriting_model_2",
    remove_unused_columns=False,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=5e-5,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    per_device_eval_batch_size=4,
    num_train_epochs=5,
    warmup_ratio=0.1,
    logging_steps=10,
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    push_to_hub=False,
)

trainer = Trainer(
    model=model,
    args=training_args,
    data_collator=data_collator,
    train_dataset=data["train"],
    eval_dataset=data["test"],
    tokenizer=image_processor,
    compute_metrics=compute_metrics,
)

trainer.train()

model.config

from PIL import Image
blue_control = Image.open("/content/blue_control.jpg")
blue_patient = Image.open("/content/blue_patient.jpg")
black_control = Image.open("/content/black_control.jpg")
black_patient = Image.open("/content/black_patient.jpg")

blue_control_wave = Image.open("/content/blue_control_wave.jpg")
blue_patient_wave = Image.open("/content/blue_patient_wave.jpg")
black_control_wave = Image.open("/content/black_control_wave.jpg")
black_patient_wave = Image.open("/content/black_patient_wave.jpg")

image_processor = AutoImageProcessor.from_pretrained("/content/new_alzheimers_handwriting_model_2/checkpoint-50")
inputs = image_processor(black_control_wave, return_tensors="pt")

model = AutoModelForImageClassification.from_pretrained("/content/new_alzheimers_handwriting_model_2/checkpoint-50")
with torch.no_grad():
    logits = model(**inputs).logits

predicted_label = logits.argmax(-1).item()
model.config.id2label[predicted_label]

"""## Making an interface"""

!pip install gradio

import gradio as gr
from keras.models import load_model
import torch.nn.functional as F
import tensorflow as tf
import io

def sketch_recognition(spiral, wave):
    image_processor = AutoImageProcessor.from_pretrained("/content/drive/MyDrive/Assignments/new_alzheimers_handwriting_model/checkpoint-30")
    inputs = image_processor(spiral, return_tensors="pt")

    model = AutoModelForImageClassification.from_pretrained("/content/drive/MyDrive/Assignments/new_alzheimers_handwriting_model/checkpoint-30")
    with torch.no_grad():
        logits = model(**inputs).logits

    predicted_label = logits.argmax(-1).item()
    spiral_label = model.config.id2label[predicted_label]
    # spiral_proba = torch.max(F.softmax(logits[0])) * 100

    image_processor = AutoImageProcessor.from_pretrained("/content/drive/MyDrive/Assignments/new_alzheimers_handwriting_model/checkpoint-30")
    inputs = image_processor(wave, return_tensors="pt")

    model = AutoModelForImageClassification.from_pretrained("/content/drive/MyDrive/Assignments/new_alzheimers_handwriting_model/checkpoint-30")
    with torch.no_grad():
        logits = model(**inputs).logits

    predicted_label = logits.argmax(-1).item()
    wave_label = model.config.id2label[predicted_label]
    # wave_proba = torch.max(F.softmax(logits[0])) * 100

    # percentage = torch.mean(torch.stack([spiral_proba, wave_proba]))

    if spiral_label == "Patient" and wave_label == "Patient":
      return "See a doctor. You may have Parkinson's Disease."
    elif spiral_label == "Control" and wave_label == "Control":
      return "You are healthy."
    else:
      return "Inconclusive results. Try test again."

def load_and_preprocess_image(img):
  # img = tf.image.decode_image(img, channels=3)
  img = tf.image.resize(img, [128, 128])
  img = tf.cast(img, tf.float32) / 255.0
  return img

def mri_classification(img):
  sample_image = load_and_preprocess_image(img)
  sample_image_preprocessed = np.expand_dims(sample_image, axis=0)

  model = load_model("/content/drive/MyDrive/Assignments/mri_cnn.h5")
  predicted_probabilities = model.predict(sample_image_preprocessed)[0]

  class_labels = ['Non Demented', 'Mild Dementia', 'Moderate Dementia', 'Very mild Dementia']
  predicted_class_index = np.argmax(predicted_probabilities)
  predicted_class_label = class_labels[predicted_class_index]
  confidence = predicted_probabilities[predicted_class_index]

  if predicted_class_label == 'Non Demented':
    return "You are healthy."
  else:
    return f"See a doctor. You may have {predicted_class_label}."

sketch_demo = gr.Interface(
    sketch_recognition,
    inputs=[gr.Image(type="pil"), gr.Image(type="pil")],
    outputs="label",
)

mri_demo = gr.Interface(
    mri_classification,
    gr.Image(),
    "label",
)

demo = gr.TabbedInterface([sketch_demo, mri_demo], ["Handwriting Classification", "MRI Classification"], theme=gr.themes.Soft()).launch(share=True, debug=True)

